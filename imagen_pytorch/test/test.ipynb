{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruhuandeng/anaconda3/envs/Deng_Unet/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ruhuandeng/anaconda3/envs/Deng_Unet/lib/python3.9/site-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TRANSFORMERS_OFFLINE'] = '1'\n",
    "\n",
    "from imagen_pytorch.trainer import ImagenTrainer\n",
    "from imagen_pytorch.configs import ImagenConfig\n",
    "from imagen_pytorch import Unet1d, Imagen\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR,StepLR,ReduceLROnPlateau\n",
    "from sklearn.metrics import cohen_kappa_score,f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "* Define all the calss and instance needed\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_input:(1000, 4000, 1), val_input:(250, 4000, 1), train_target:(1000, 4000, 11), val_target:(250, 4000, 11)\n"
     ]
    }
   ],
   "source": [
    "class ION_Dataset(Dataset):\n",
    "    def __init__(self, train_input, train_output,mode='train'):\n",
    "        self.train_input = train_input\n",
    "        self.train_output = train_output\n",
    "        self.mode = mode\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.train_input)\n",
    "    \n",
    "    def _augmentations(self,input_data, target_data):\n",
    "        #flip\n",
    "        if np.random.rand()<0.5:    \n",
    "            input_data = input_data[::-1]\n",
    "            target_data = target_data[::-1]\n",
    "        return input_data, target_data\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.train_input[idx]\n",
    "        y = self.train_output[idx]\n",
    "        if self.mode =='train':\n",
    "            x,y = self._augmentations(x,y)\n",
    "        out_x = torch.tensor(np.transpose(x.copy(),(1,0)), dtype=torch.float) # This makes [b, c, l] format\n",
    "        out_y = torch.tensor(np.transpose(y.copy(),(1,0)), dtype=torch.float)\n",
    "        return out_x, out_y\n",
    "    \n",
    "### DEFINE DATALOADER ###\n",
    "df_train = pd.read_csv(\"./Data/liverpool-ion-switching/train.csv\")\n",
    "df_test = pd.read_csv(\"./Data/liverpool-ion-switching/test.csv\")\n",
    "\n",
    "# I don't use \"time\" feature\n",
    "train_input = df_train[\"signal\"].values.reshape(-1,4000,1)#number_of_data:1250 x time_step:4000, this shape is not in [b, c, l] format yet\n",
    "train_input_mean = train_input.mean()\n",
    "train_input_sigma = train_input.std()\n",
    "train_input = (train_input-train_input_mean)/train_input_sigma\n",
    "test_input = df_test[\"signal\"].values.reshape(-1,10000,1)\n",
    "test_input = (test_input-train_input_mean)/train_input_sigma\n",
    "\n",
    "train_target = pd.get_dummies(df_train[\"open_channels\"]).values.reshape(-1,4000,11)#classification\n",
    "\n",
    "idx = np.arange(train_input.shape[0])\n",
    "train_idx, val_idx = train_test_split(idx, random_state = 111,test_size = 0.2)\n",
    "\n",
    "val_input = train_input[val_idx]\n",
    "train_input = train_input[train_idx] \n",
    "val_target = train_target[val_idx]\n",
    "train_target = train_target[train_idx] \n",
    "\n",
    "print(\"train_input:{}, val_input:{}, train_target:{}, val_target:{}\".format(train_input.shape, val_input.shape, train_target.shape, val_target.shape))\n",
    "    \n",
    "unet1 = Unet1d(\n",
    "        dim=128,\n",
    "        text_embed_dim = None,\n",
    "        num_resnet_blocks = 1,\n",
    "        cond_dim = None,\n",
    "        num_image_tokens = None,\n",
    "        num_time_tokens = None,\n",
    "        learned_sinu_pos_emb_dim = 0,\n",
    "        out_dim = None,\n",
    "        dim_mults=(1, 2, 4, 8),\n",
    "        cond_images_channels = 0,\n",
    "        channels = 1,\n",
    "        channels_out = 11,\n",
    "        attn_dim_head = 0,\n",
    "        attn_heads = 2, # But should not be used at all\n",
    "        ff_mult = 2.,\n",
    "        lowres_cond = False,                # for cascading diffusion - https://cascaded-diffusion.github.io/\n",
    "        layer_attns = False,\n",
    "        layer_attns_depth = 0,\n",
    "        layer_mid_attns_depth = 0,\n",
    "        layer_attns_add_text_cond = False,   # whether to condition the self-attention blocks with the text embeddings, as described in Appendix D.3.1\n",
    "        attend_at_middle = False,            # whether to have a layer of attention at the bottleneck (can turn off for higher resolution in cascading DDPM, before bringing in efficient attention)\n",
    "        layer_cross_attns = False,\n",
    "        use_linear_attn = False,\n",
    "        use_linear_cross_attn = False,\n",
    "        cond_on_text = False,\n",
    "        max_text_len = 0,\n",
    "        init_dim = None,\n",
    "        init_conv_kernel_size = 7,          # kernel size of initial conv, if not using cross embed\n",
    "        init_cross_embed = True,\n",
    "        init_cross_embed_kernel_sizes = (3, 7, 15),\n",
    "        cross_embed_downsample = False,\n",
    "        cross_embed_downsample_kernel_sizes = (2, 4),\n",
    "        attn_pool_text = False,\n",
    "        attn_pool_num_latents = 0,\n",
    "        dropout = 0.,\n",
    "        memory_efficient = False,\n",
    "        init_conv_to_final_conv_residual = False,\n",
    "        use_global_context_attn = False,\n",
    "        scale_skip_connection = True,\n",
    "        final_resnet_block = True,\n",
    "        final_conv_kernel_size = 3,\n",
    "        self_cond = False,\n",
    "        resize_mode = 'nearest',\n",
    "        combine_upsample_fmaps = False,      # combine feature maps from all upsample blocks, used in unet squared successfully\n",
    "        pixel_shuffle_upsample = False,       # may address checkboard artifacts, have problem with 1D case\n",
    "    )\n",
    "\n",
    "batch_size = 8\n",
    "train = ION_Dataset(train_input, train_target,mode='train')\n",
    "valid = ION_Dataset(val_input, val_target,mode='valid')\n",
    "\n",
    "x_test = torch.tensor(np.transpose(test_input,(0,2,1)), dtype=torch.float).cuda()\n",
    "test = torch.utils.data.TensorDataset(x_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TRAINING ####\n",
    "## Hyperparameter\n",
    "n_epochs = 100\n",
    "lr = 0.001\n",
    "\n",
    "## Build tensor data for torch\n",
    "train_preds = np.zeros((int(train_input.shape[0]*train_input.shape[1])))\n",
    "val_preds = np.zeros((int(val_input.shape[0]*val_input.shape[1])))\n",
    "\n",
    "train_targets = np.zeros((int(train_input.shape[0]*train_input.shape[1])))\n",
    "\n",
    "avg_losses_f = []\n",
    "avg_val_losses_f = []\n",
    "\n",
    "##Loss function\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "#Build model, initial weight and optimizer\n",
    "model = unet1\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr,weight_decay=1e-5) # Using Adam optimizer\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.8, min_lr=1e-8) # Using ReduceLROnPlateau schedule\n",
    "temp_val_loss = 9999999999\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    avg_loss = 0.\n",
    "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        y_pred = model(x_batch.cuda(), time=0) # Time here is a dummy variable\n",
    "        \n",
    "        loss = loss_fn(y_pred.cpu(), y_batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item()/len(train_loader)\n",
    "\n",
    "        pred = F.softmax(y_pred, 1).detach().cpu().numpy().argmax(axis=1)\n",
    "        train_preds[i * batch_size*train_input.shape[1]:(i+1) * batch_size*train_input.shape[1]] = pred.reshape((-1))\n",
    "        train_targets[i * batch_size*train_input.shape[1]:(i+1) * batch_size*train_input.shape[1]] = y_batch.detach().cpu().argmax(axis=1).reshape((-1))\n",
    "        del y_pred, loss, x_batch, y_batch, pred\n",
    "        \n",
    "        \n",
    "    model.eval()\n",
    "\n",
    "    avg_val_loss = 0.\n",
    "    for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
    "        y_pred = model(x_batch.cuda()).detach()\n",
    "\n",
    "        avg_val_loss += loss_fn(y_pred.cpu(), y_batch).item() / len(valid_loader)\n",
    "        pred = F.softmax(y_pred, 1).detach().cpu().numpy().argmax(axis=1)\n",
    "        val_preds[i * batch_size*val_input.shape[1]:(i+1) * batch_size*val_input.shape[1]] = pred.reshape((-1))\n",
    "        del y_pred, x_batch, y_batch, pred\n",
    "        \n",
    "    if avg_val_loss<temp_val_loss:\n",
    "        #print ('checkpoint_save')\n",
    "        temp_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), './Model/liverpool-ion-switching/ION_train_checkpoint.pt')\n",
    "        \n",
    "    train_score = f1_score(train_targets,train_preds,average = 'macro')\n",
    "    val_score = f1_score(val_target.argmax(axis=2).reshape((-1)),val_preds,average = 'macro')\n",
    "    \n",
    "    elapsed_time = time.time() - start_time \n",
    "    scheduler.step(avg_val_loss)\n",
    "    \n",
    "    print('Epoch {}/{} \\t loss={:.4f} \\t train_f1={:.4f} \\t val_loss={:.4f} \\t val_f1={:.4f} \\t time={:.2f}s'.format(\n",
    "        epoch + 1, n_epochs, avg_loss,train_score, avg_val_loss,val_score, elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deng_Unet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
